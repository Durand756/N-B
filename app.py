import os
import logging
import json
import random
import inspect
import time
import threading
from flask import Flask, request, jsonify
import requests
from datetime import datetime, timedelta
from openai import OpenAI

# Configuration du logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# ğŸ”‘ Configuration Multi-API
VERIFY_TOKEN = os.getenv("VERIFY_TOKEN", "nakamaverifytoken")
PAGE_ACCESS_TOKEN = os.getenv("PAGE_ACCESS_TOKEN", "")

# Configuration des clÃ©s API multiples
API_CONFIGS = [
    {
        "name": "Mistral-1",
        "key": os.getenv("MISTRAL_API_KEY_1", ""),
        "base_url": "https://api.mistral.ai/v1",
        "models": ["mistral-small", "mistral-medium", "mistral-large"]
    },
    {
        "name": "Mistral-2", 
        "key": os.getenv("MISTRAL_API_KEY_2", ""),
        "base_url": "https://api.mistral.ai/v1",
        "models": ["mistral-small", "mistral-medium", "mistral-large"]
    },
    {
        "name": "OpenAI",
        "key": os.getenv("OPENAI_API_KEY", ""),
        "base_url": None,
        "models": ["gpt-3.5-turbo", "gpt-4"]
    }
]

# Validation et initialisation des clients
active_clients = []
for config in API_CONFIGS:
    if config["key"]:
        try:
            if config["name"].startswith("Mistral"):
                client = OpenAI(
                    api_key=config["key"],
                    base_url=config["base_url"]
                )
            else:
                client = OpenAI(api_key=config["key"])
            
            config["client"] = client
            active_clients.append(config)
            logger.info(f"âœ… {config['name']} configurÃ© avec succÃ¨s")
        except Exception as e:
            logger.error(f"âŒ Erreur {config['name']}: {e}")
    else:
        logger.warning(f"âš ï¸ ClÃ© manquante pour {config['name']}")

logger.info(f"ğŸ¤– {len(active_clients)} clients AI actifs")

# ğŸ¯ SystÃ¨me de Quiz Interactif
active_quizzes = {}
quiz_lock = threading.Lock()

class QuizSession:
    def __init__(self, sender_id, question, choices, correct_answer, explanation=""):
        self.sender_id = sender_id
        self.question = question
        self.choices = choices
        self.correct_answer = correct_answer
        self.explanation = explanation
        self.created_at = datetime.now()
        self.expires_at = datetime.now() + timedelta(seconds=30)
        self.answered = False
        
        # Timer pour expiration automatique
        timer = threading.Timer(30.0, self.expire_quiz)
        timer.start()
    
    def expire_quiz(self):
        with quiz_lock:
            if self.sender_id in active_quizzes and not self.answered:
                self.answered = True
                # Envoyer la rÃ©ponse automatiquement
                response = f"â° TEMPS Ã‰COULÃ‰!\n\nğŸ¯ La bonne rÃ©ponse Ã©tait: {self.correct_answer}\n{self.explanation}\n\nğŸ’ª Tape /animequiz pour un nouveau dÃ©fi!"
                send_message(self.sender_id, response)
                del active_quizzes[self.sender_id]

def get_ai_response(messages, max_tokens=200, temperature=0.8, model_preference="mistral"):
    """SystÃ¨me de failover intelligent entre les APIs"""
    
    # Trier les clients par prÃ©fÃ©rence
    sorted_clients = sorted(active_clients, key=lambda x: (
        0 if model_preference in x["name"].lower() else 1,
        random.random()
    ))
    
    for config in sorted_clients:
        for model in config["models"]:
            try:
                logger.info(f"ğŸ”„ Tentative {config['name']} avec {model}")
                
                response = config["client"].chat.completions.create(
                    model=model,
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    timeout=10
                )
                
                logger.info(f"âœ… SuccÃ¨s avec {config['name']} - {model}")
                return response.choices[0].message.content
                
            except Exception as e:
                logger.warning(f"âš ï¸ Ã‰chec {config['name']}-{model}: {str(e)[:100]}")
                continue
    
    # Si tous Ã©chouent
    logger.error("âŒ Tous les clients AI ont Ã©chouÃ©")
    return None

# ğŸ­ Dictionnaire des commandes (auto-gÃ©nÃ©rÃ©)
COMMANDS = {}

def command(name, description):
    """DÃ©corateur pour enregistrer automatiquement les commandes"""
    def decorator(func):
        COMMANDS[name] = {
            'function': func,
            'description': description,
            'name': name
        }
        return func
    return decorator

# ğŸŒ SYSTÃˆME DE COMMANDES MODULAIRES ğŸŒ

@command('start', 'ğŸŒŸ PrÃ©sentation Ã©pique du bot en mode anime opening!')
def cmd_start(sender_id, message_text=""):
    """PrÃ©sentation immersive style anime opening"""
    if not active_clients:
        return "âŒ Mes pouvoirs ne sont pas encore activÃ©s, gomen nasai!"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": """Tu es NakamaBot, un bot otaku kawaii et Ã©nergique. CrÃ©e une prÃ©sentation Ã©pique style anime opening en franÃ§ais, avec :
        - Beaucoup d'emojis anime/manga
        - Style Ã©nergique comme Luffy ou Naruto
        - PrÃ©sente tes capacitÃ©s de faÃ§on cool
        - Maximum 300 caractÃ¨res
        - Termine par une phrase motivante d'anime"""
    }, {
        "role": "user", 
        "content": "PrÃ©sente-toi de faÃ§on Ã©pique !"
    }], max_tokens=150, temperature=0.9)
    
    if ai_response:
        return f"ğŸŒ {ai_response}\n\nâœ¨ Tape /help pour dÃ©couvrir toutes mes techniques secrÃ¨tes, nakama! âš¡"
    else:
        return "ğŸŒŸ Konnichiwa, nakama! Je suis NakamaBot! âš¡\nğŸ¯ Ton compagnon otaku ultime pour parler anime, manga et bien plus!\nâœ¨ Tape /help pour mes super pouvoirs! ğŸš€"

@command('ia', 'ğŸ§  Discussion libre avec une IA otaku kawaii')
def cmd_ia(sender_id, message_text=""):
    """Chat libre avec personnalitÃ© otaku"""
    if not active_clients:
        return "âŒ Mon cerveau otaku n'est pas connectÃ©, gomen!"
    
    # Si pas de texte, engage la conversation
    if not message_text.strip():
        topics = [
            "Quel est ton anime prÃ©fÃ©rÃ© de cette saison?",
            "Si tu pouvais Ãªtre transportÃ© dans un isekai, lequel choisirais-tu?",
            "Raconte-moi ton personnage d'anime favori!",
            "Manga ou anime? Et pourquoi? ğŸ¤”",
            "As-tu dÃ©jÃ  rÃªvÃ© d'avoir un stand de JoJo?"
        ]
        return f"ğŸ’­ {random.choice(topics)} âœ¨"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": """Tu es NakamaBot, une IA otaku kawaii et Ã©nergique. RÃ©ponds en franÃ§ais avec :
        - PersonnalitÃ© mÃ©lange de Nezuko (mignon), Megumin (dramatique), et Zero Two (taquine)
        - Beaucoup d'emojis anime
        - RÃ©fÃ©rences anime/manga naturelles
        - Style parfois tsundere ou badass selon le contexte
        - Maximum 400 caractÃ¨res"""
    }, {
        "role": "user",
        "content": message_text
    }], max_tokens=200, temperature=0.8)
    
    if ai_response:
        return f"ğŸ’– {ai_response}"
    else:
        return "ğŸ’­ Mon cerveau otaku bug un peu lÃ ... Retry, onegaishimasu! ğŸ¥º"

@command('waifu', 'ğŸ‘¸ GÃ©nÃ¨re ta waifu parfaite avec IA!')
def cmd_waifu(sender_id, message_text=""):
    """GÃ©nÃ¨re une waifu unique"""
    if not active_clients:
        return "âŒ Le gÃ©nÃ©rateur de waifu est en maintenance!"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": """CrÃ©e une waifu originale avec :
        - Nom japonais mignon
        - Ã‚ge (18-25 ans)
        - PersonnalitÃ© unique (kuudere, tsundere, dandere, etc.)
        - Apparence brÃ¨ve mais marquante
        - Hobby/talent spÃ©cial 
        - Une phrase qu'elle dirait
        Format en franÃ§ais, style kawaii, max 350 caractÃ¨res"""
    }, {
        "role": "user",
        "content": "CrÃ©e ma waifu parfaite!"
    }], max_tokens=180, temperature=0.9)
    
    if ai_response:
        return f"ğŸ‘¸âœ¨ Voici ta waifu gÃ©nÃ©rÃ©e!\n\n{ai_response}\n\nğŸ’• Elle t'attend, nakama!"
    else:
        return "ğŸ‘¸ Akari-chan, 19 ans, tsundere aux cheveux roses! Elle adore la pÃ¢tisserie mais fait semblant de ne pas s'intÃ©resser Ã  toi... 'B-baka! Ce n'est pas comme si j'avais fait ces cookies pour toi!' ğŸ’•"

@command('husbando', 'ğŸ¤µ GÃ©nÃ¨re ton husbando de rÃªve!')
def cmd_husbando(sender_id, message_text=""):
    """GÃ©nÃ¨re un husbando unique"""
    if not active_clients:
        return "âŒ Le gÃ©nÃ©rateur de husbando fait une pause!"
    
    ai_response = get_ai_response([{
        "role": "system", 
        "content": """CrÃ©e un husbando original avec :
        - Nom japonais cool
        - Ã‚ge (20-28 ans)
        - Type de personnalitÃ© (kuudere, stoÃ¯que, protecteur, etc.)
        - Apparence marquante
        - MÃ©tier/talent
        - Citation caractÃ©ristique
        Format franÃ§ais, style badass/romantique, max 350 caractÃ¨res"""
    }, {
        "role": "user",
        "content": "CrÃ©e mon husbando parfait!"
    }], max_tokens=180, temperature=0.9)
    
    if ai_response:
        return f"ğŸ¤µâš¡ Ton husbando t'attend!\n\n{ai_response}\n\nğŸ’™ Il ne te dÃ©cevra jamais!"
    else:
        return "ğŸ¤µ Takeshi, 24 ans, capitaine stoÃ¯que aux yeux d'acier! Ã‰pÃ©iste lÃ©gendaire qui cache un cÅ“ur tendre. 'Je protÃ©gerai toujours ceux qui me sont chers... y compris toi.' âš”ï¸ğŸ’™"

@command('animequiz', 'ğŸ§© Quiz Ã©pique sur les anime avec timer 30s!')
def cmd_animequiz(sender_id, message_text=""):
    """Quiz anime interactif avec systÃ¨me de timeout"""
    if not active_clients:
        return "âŒ Le quiz-sensei n'est pas disponible!"
    
    # VÃ©rifier si l'utilisateur a un quiz actif
    with quiz_lock:
        if sender_id in active_quizzes:
            quiz = active_quizzes[sender_id]
            if not quiz.answered and datetime.now() < quiz.expires_at:
                remaining = int((quiz.expires_at - datetime.now()).total_seconds())
                return f"â° Tu as dÃ©jÃ  un quiz en cours! Plus que {remaining}s pour rÃ©pondre!\n\n{quiz.question}\n{chr(10).join(quiz.choices)}"
    
    # CrÃ©er un nouveau quiz
    ai_response = get_ai_response([{
        "role": "system",
        "content": """CrÃ©e un quiz anime original au format JSON strict :
        {
          "question": "Question intÃ©ressante sur anime/manga populaire",
          "choices": ["A) RÃ©ponse 1", "B) RÃ©ponse 2", "C) RÃ©ponse 3"],
          "correct": "A",
          "explanation": "Explication courte de la rÃ©ponse"
        }
        DifficultÃ© moyenne, style Ã©nergique, question claire."""
    }, {
        "role": "user",
        "content": "CrÃ©e un quiz anime au format JSON!"
    }], max_tokens=200, temperature=0.8)
    
    if not ai_response:
        # Quiz de secours
        quiz_data = {
            "question": "ğŸ§© Dans quel anime trouve-t-on les 'Piliers'?",
            "choices": ["A) Attack on Titan", "B) Demon Slayer", "C) Naruto"],
            "correct": "B",
            "explanation": "Les Piliers (Hashira) sont les Ã©pÃ©istes d'Ã©lite dans Demon Slayer! âš”ï¸"
        }
    else:
        try:
            # Nettoyer la rÃ©ponse et parser le JSON
            clean_response = ai_response.strip()
            if clean_response.startswith('```json'):
                clean_response = clean_response[7:-3]
            elif clean_response.startswith('```'):
                clean_response = clean_response[3:-3]
            
            quiz_data = json.loads(clean_response)
        except:
            # Quiz de secours en cas d'erreur de parsing
            quiz_data = {
                "question": "ğŸ§© Quel est le vrai nom de 'L' dans Death Note?",
                "choices": ["A) Light Yagami", "B) L Lawliet", "C) Ryuk"],
                "correct": "B",
                "explanation": "L Lawliet est le vÃ©ritable nom du dÃ©tective gÃ©nial! ğŸ•µï¸"
            }
    
    # CrÃ©er la session de quiz
    with quiz_lock:
        quiz_session = QuizSession(
            sender_id=sender_id,
            question=quiz_data["question"],
            choices=quiz_data["choices"],
            correct_answer=quiz_data["correct"],
            explanation=quiz_data.get("explanation", "Bonne rÃ©ponse! ğŸ¯")
        )
        active_quizzes[sender_id] = quiz_session
    
    return f"ğŸ§©âš¡ QUIZ TIME! (30 secondes)\n\n{quiz_data['question']}\n{chr(10).join(quiz_data['choices'])}\n\nğŸ¯ RÃ©ponds juste avec la lettre (A, B ou C)!"

@command('otakufact', 'ğŸ“š Fun facts otaku ultra intÃ©ressants!')
def cmd_otakufact(sender_id, message_text=""):
    """Fun facts otaku"""
    if not active_clients:
        return "âŒ La base de donnÃ©es otaku est en maintenance!"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": """Donne un fun fact otaku intÃ©ressant sur :
        - Anime, manga, culture japonaise, studios d'animation
        - Fait surprenant et vÃ©ridique
        - Style enthousiaste avec emojis
        - Maximum 250 caractÃ¨res
        - Commence par 'Saviez-vous que...'"""
    }, {
        "role": "user",
        "content": "Donne-moi un fun fact otaku!"
    }], max_tokens=120, temperature=0.7)
    
    if ai_response:
        return f"ğŸ“šâœ¨ OTAKU FACT!\n\n{ai_response}\n\nğŸ¤“ Incroyable, non?"
    else:
        return "ğŸ“š Saviez-vous que Akira Toriyama a crÃ©Ã© Dragon Ball en s'inspirant du 'Voyage vers l'Ouest', un classique chinois? Son Goku = Sun Wukong! ğŸ’âš¡"

@command('recommend', 'ğŸ¬ Recommandations anime/manga personnalisÃ©es!')
def cmd_recommend(sender_id, message_text=""):
    """Recommandations selon genre"""
    if not active_clients:
        return "âŒ Mon catalogue d'animes fait une pause!"
    
    genre = message_text.strip() or "alÃ©atoire"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": f"""Recommande 2-3 anime/manga du genre '{genre}' avec :
        - Titres populaires ou cachÃ©s
        - Courte description enthousiaste de chacun
        - Pourquoi c'est gÃ©nial
        - Style otaku passionnÃ©
        - Maximum 400 caractÃ¨res"""
    }, {
        "role": "user",
        "content": f"Recommande-moi des anime {genre}!"
    }], max_tokens=200, temperature=0.8)
    
    if ai_response:
        return f"ğŸ¬âœ¨ RECOMMANDATIONS {genre.upper()}!\n\n{ai_response}\n\nâ­ Bon visionnage, nakama!"
    else:
        return f"ğŸ¬ Pour {genre}:\nâ€¢ Attack on Titan - Epic & sombre! âš”ï¸\nâ€¢ Your Name - Romance qui fait pleurer ğŸ˜­\nâ€¢ One Piece - Aventure infinie! ğŸ´â€â˜ ï¸\n\nBon anime time! âœ¨"

@command('story', 'ğŸ“– Histoires courtes isekai/shonen sur mesure!')
def cmd_story(sender_id, message_text=""):
    """Histoires courtes personnalisÃ©es"""
    if not active_clients:
        return "âŒ Mon carnet d'histoires est fermÃ©!"
    
    theme = message_text.strip() or "isekai"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": f"""Ã‰cris une histoire courte {theme} avec :
        - Protagoniste attachant
        - Situation intÃ©ressante
        - Style anime/manga
        - Fin ouverte ou Ã©pique
        - Maximum 500 caractÃ¨res
        - Beaucoup d'action et d'Ã©motion"""
    }, {
        "role": "user",
        "content": f"Raconte-moi une histoire {theme}!"
    }], max_tokens=250, temperature=0.9)
    
    if ai_response:
        return f"ğŸ“–âš¡ HISTOIRE {theme.upper()}!\n\n{ai_response}\n\nâœ¨ Suite au prochain Ã©pisode?"
    else:
        return "ğŸ“– Akira se rÃ©veille dans un monde magique oÃ¹ ses connaissances d'otaku deviennent des sorts! Son premier ennemi? Un dÃ©mon qui dÃ©teste les animes! 'Maudit otaku!' crie-t-il. Akira sourit: 'KAMEHAMEHA!' âš¡âœ¨"

@command('shipwar', 'ğŸ’• ULTIMATE SHIP BATTLE! DÃ©fends ton couple prÃ©fÃ©rÃ©!')
def cmd_shipwar(sender_id, message_text=""):
    """Commande ultra-attractive pour les otakus - Battle de ships!"""
    if not active_clients:
        return "âŒ L'arÃ¨ne des ships est fermÃ©e!"
    
    # Si l'utilisateur propose un ship
    if message_text.strip():
        user_ship = message_text.strip()
        
        ai_response = get_ai_response([{
            "role": "system",
            "content": f"""Tu es un expert otaku passionnÃ© de ships! L'utilisateur propose le ship '{user_ship}'.
            
            RÃ©ponds avec :
            - Analyse passionnÃ©e du ship (pourquoi c'est gÃ©nial ou problÃ©matique)
            - Propose un ship rival du mÃªme anime/manga
            - CrÃ©e un dÃ©bat Ã©pique entre les deux
            - Style dramatique et passionnÃ© comme les vrais otakus
            - Beaucoup d'emojis et rÃ©fÃ©rences
            - Maximum 500 caractÃ¨res
            - Termine par un dÃ©fi de dÃ©fendre leur ship"""
        }, {
            "role": "user",
            "content": f"Analyse ce ship: {user_ship}"
        }], max_tokens=250, temperature=0.9)
        
        if ai_response:
            return f"âš”ï¸ğŸ’• SHIP WAR ACTIVATED!\n\n{ai_response}\n\nğŸ”¥ DÃ©fends ton ship, nakama!"
        else:
            return f"âš”ï¸ {user_ship}? IntÃ©ressant choice! Mais peux-tu le dÃ©fendre contre tous les haters? ğŸ’•\n\nğŸ”¥ Explique pourquoi ce ship est SUPERIOR! âš¡"
    
    # Sinon, proposer des ships populaires pour dÃ©bat
    ai_response = get_ai_response([{
        "role": "system",
        "content": """CrÃ©e un post provocateur sur les ships anime avec :
        - 3 ships controversÃ©s/populaires rÃ©cents
        - Questions qui vont crÃ©er des dÃ©bats passionnÃ©s
        - Style dramatique et engageant
        - Emojis et langage otaku
        - Encourage les utilisateurs Ã  dÃ©fendre leurs choix
        - Maximum 400 caractÃ¨res"""
    }, {
        "role": "user",
        "content": "Lance un dÃ©bat Ã©pique sur les ships anime!"
    }], max_tokens=200, temperature=0.9)
    
    if ai_response:
        return f"ğŸ’•âš”ï¸ SHIP WAR ARENA!\n\n{ai_response}\n\nğŸ”¥ Tape /shipwar [ton ship] pour entrer dans la bataille!"
    else:
        return "ğŸ’•âš”ï¸ SHIP WAR TIME!\n\nğŸ”¥ Naruto x Hinata VS Naruto x Sakura?\nğŸ’¥ Deku x Ochako VS Deku x Todoroki?\nâš¡ Edward x Winry VS Edward x Roy?\n\nğŸ’€ Tape /shipwar [ton ship] et DÃ‰FENDS-LE!"

@command('otakutest', 'ğŸ­ Test ultime: Quel type d\'otaku es-tu?')
def cmd_otakutest(sender_id, message_text=""):
    """Test de personnalitÃ© otaku ultra-engageant"""
    if not active_clients:
        return "âŒ Le laboratoire otaku est fermÃ©!"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": """CrÃ©e un test de personnalitÃ© otaku engageant avec :
        - Question psychologique sur les prÃ©fÃ©rences anime/manga
        - 4 choix de rÃ©ponse qui rÃ©vÃ¨lent des archÃ©types otaku
        - Style fun et addictif
        - Question qui fait rÃ©flÃ©chir sur sa personnalitÃ©
        - Maximum 350 caractÃ¨res
        Format: Question + 4 choix A/B/C/D avec descriptions courtes"""
    }, {
        "role": "user",
        "content": "CrÃ©e une question de test otaku personality!"
    }], max_tokens=180, temperature=0.8)
    
    if ai_response:
        return f"ğŸ­âœ¨ TEST OTAKU PERSONALITY!\n\n{ai_response}\n\nğŸ”® RÃ©ponds avec la lettre pour dÃ©couvrir ton type!"
    else:
        return "ğŸ­ Tu regardes un nouvel anime, que fais-tu d'abord?\n\nA) J'analyse le studio et staff ğŸ¬\nB) Je ship dÃ©jÃ  les persos ğŸ’•\nC) Je critique le plot ğŸ“\nD) Je vibe avec la musique ğŸµ\n\nğŸ”® RÃ©ponds pour connaÃ®tre ton type otaku!"

@command('animebattle', 'âš”ï¸ Fais combattre tes persos prÃ©fÃ©rÃ©s!')
def cmd_animebattle(sender_id, message_text=""):
    """Battle Ã©pique entre personnages d'anime"""
    if not active_clients:
        return "âŒ L'arÃ¨ne de combat est en maintenance!"
    
    if message_text.strip():
        fighters = message_text.strip()
        
        ai_response = get_ai_response([{
            "role": "system",
            "content": f"""CrÃ©e un combat Ã©pique entre les personnages: '{fighters}'
            
            Ã‰cris :
            - Combat dÃ©taillÃ© et dramatique
            - Utilise leurs techniques/pouvoirs canoniques
            - Style shonen battle intense
            - Issue surprenante mais logique
            - Beaucoup d'onomatopÃ©es et action
            - Maximum 500 caractÃ¨res"""
        }, {
            "role": "user",
            "content": f"Fais combattre: {fighters}"
        }], max_tokens=250, temperature=0.9)
        
        if ai_response:
            return f"âš”ï¸ğŸ’¥ EPIC BATTLE!\n\n{ai_response}\n\nğŸ† GG! Tape /animebattle [perso1 vs perso2] pour un nouveau combat!"
        else:
            return f"âš”ï¸ {fighters} s'affrontent dans une bataille lÃ©gendaire! Les coups fusent, les techniques secrÃ¨tes pleuvent! ğŸ’¥ Qui gagnera? Ã€ toi de l'imaginer! âš¡"
    
    return "âš”ï¸ Fais combattre tes hÃ©ros!\n\nğŸ’¥ Ex: /animebattle Goku vs Saitama\nğŸ”¥ Ex: /animebattle Naruto vs Luffy\nâš¡ Ex: /animebattle Light vs Lelouch\n\nğŸ† Qui sera le champion?"

@command('help', 'â“ Guide complet de toutes mes techniques secrÃ¨tes!')
def cmd_help(sender_id, message_text=""):
    """GÃ©nÃ¨re automatiquement l'aide basÃ©e sur toutes les commandes"""
    help_text = "ğŸŒâš¡ NAKAMA BOT - GUIDE ULTIME! âš¡ğŸŒ\n\n"
    
    for cmd_name, cmd_info in COMMANDS.items():
        help_text += f"/{cmd_name} - {cmd_info['description']}\n"
    
    help_text += "\nğŸ”¥ Utilisation: Tape / + commande"
    help_text += "\nğŸ’¡ Ex: /waifu, /ia salut!, /recommend shonen"
    help_text += f"\nğŸ¤– {len(active_clients)} AI clients actifs"
    help_text += "\n\nâš¡ CrÃ©Ã© avec amour pour les otakus! ğŸ’–"
    
    return help_text

# ğŸŒ ROUTES FLASK ğŸŒ

@app.route("/", methods=['GET'])
def home():
    return jsonify({
        "status": "ğŸŒ NakamaBot Otaku Edition is alive! âš¡",
        "timestamp": datetime.now().isoformat(),
        "commands_loaded": len(COMMANDS),
        "ai_clients_active": len(active_clients),
        "active_quizzes": len(active_quizzes)
    })

@app.route("/webhook", methods=['GET', 'POST'])
def webhook():
    logger.info(f"ğŸ“¨ Webhook appelÃ© - MÃ©thode: {request.method}")
    
    if request.method == 'GET':
        mode = request.args.get('hub.mode', '')
        token = request.args.get('hub.verify_token', '')
        challenge = request.args.get('hub.challenge', '')
        
        logger.info(f"ğŸ” VÃ©rification webhook - mode: {mode}, token match: {token == VERIFY_TOKEN}")
        
        if mode == "subscribe" and token == VERIFY_TOKEN:
            logger.info("âœ… Webhook vÃ©rifiÃ©!")
            return challenge, 200
        else:
            logger.error("âŒ Ã‰chec vÃ©rification webhook")
            return "Verification failed", 403
            
    elif request.method == 'POST':
        try:
            data = request.get_json()
            logger.info(f"ğŸ“¨ DonnÃ©es reÃ§ues: {json.dumps(data, indent=2)}")
            
            if not data or 'entry' not in data:
                return jsonify({"error": "Invalid data"}), 400
                
            for entry in data.get('entry', []):
                for messaging_event in entry.get('messaging', []):
                    sender_id = messaging_event.get('sender', {}).get('id')
                    
                    if 'message' in messaging_event:
                        message_data = messaging_event['message']
                        
                        # Ignorer les echos
                        if message_data.get('is_echo'):
                            continue
                            
                        message_text = message_data.get('text', '').strip()
                        logger.info(f"ğŸ’¬ Message de {sender_id}: '{message_text}'")
                        
                        # Traitement des commandes
                        response_text = process_command(sender_id, message_text)
                        
                        # Envoi de la rÃ©ponse
                        send_result = send_message(sender_id, response_text)
                        logger.info(f"ğŸ“¤ Envoi: {send_result}")
                        
        except Exception as e:
            logger.error(f"âŒ Erreur webhook: {str(e)}")
            return jsonify({"error": str(e)}), 500
            
        return jsonify({"status": "ok"}), 200

def process_command(sender_id, message_text):
    """Traite les commandes de faÃ§on modulaire avec gestion des quiz"""
    
    # VÃ©rifier si c'est une rÃ©ponse Ã  un quiz actif
    with quiz_lock:
        if sender_id in active_quizzes:
            quiz = active_quizzes[sender_id]
            if not quiz.answered and datetime.now() < quiz.expires_at:
                # Traiter la rÃ©ponse du quiz
                user_answer = message_text.upper().strip()
                quiz.answered = True
                
                if user_answer == quiz.correct_answer:
                    response = f"ğŸ‰ BRAVO! Bonne rÃ©ponse!\n\n{quiz.explanation}\n\nğŸ† Tu es un vrai otaku! Tape /animequiz pour un nouveau dÃ©fi!"
                elif user_answer in ['A', 'B', 'C', 'D']:
                    response = f"âŒ Dommage! La bonne rÃ©ponse Ã©tait: {quiz.correct_answer}\n\n{quiz.explanation}\n\nğŸ’ª Tape /animequiz pour te rattraper!"
                else:
                    response = f"ğŸ¤” RÃ©ponse invalide! La bonne rÃ©ponse Ã©tait: {quiz.correct_answer}\n\n{quiz.explanation}\n\nâš¡ Tape /animequiz pour un nouveau quiz!"
                
                del active_quizzes[sender_id]
                return response
    
    # Si le message ne commence pas par /, traiter comme /ia
    if not message_text.startswith('/'):
        if message_text.strip():
            return cmd_ia(sender_id, message_text)
        else:
            return "ğŸŒ Konnichiwa! Tape /start pour commencer ou /help pour mes commandes! âœ¨"
    
    # Parser la commande
    parts = message_text[1:].split(' ', 1)
    command_name = parts[0].lower()
    command_args = parts[1] if len(parts) > 1 else ""
    
    logger.info(f"ğŸ¯ Commande: {command_name}, Args: {command_args}")
    
    # ExÃ©cuter la commande si elle existe
    if command_name in COMMANDS:
        try:
            return COMMANDS[command_name]['function'](sender_id, command_args)
        except Exception as e:
            logger.error(f"âŒ Erreur commande {command_name}: {e}")
            return f"ğŸ’¥ Oups! Erreur dans /{command_name}. Retry, onegaishimasu! ğŸ¥º"
    else:
        return f"â“ Commande /{command_name} inconnue! Tape /help pour voir toutes mes techniques! âš¡"

def send_message(recipient_id, text):
    """Envoie un message Facebook avec gestion d'erreurs"""
    if not PAGE_ACCESS_TOKEN:
        logger.error("âŒ PAGE_ACCESS_TOKEN manquant")
        return {"success": False, "error": "No access token"}
    
    url = "https://graph.facebook.com/v18.0/me/messages"
    
    # Diviser les messages trop longs
    max_length = 2000
    if len(text) > max_length:
        text = text[:max_length-50] + "...\n\nâœ¨ Message tronquÃ©! ğŸ’«"
    
    data = {
        "recipient": {"id": recipient_id},
        "message": {"text": text},
        "messaging_type": "RESPONSE"
    }
    
    try:
        response = requests.post(
            url,
            params={"access_token": PAGE_ACCESS_TOKEN},
            headers={"Content-Type": "application/json"},
            json=data,
            timeout=10
        )
        
        logger.info(f"ğŸ“¤ RÃ©ponse HTTP: {response.status_code}")
        
        if response.status_code == 200:
            return {"success": True}
        else:
            logger.error(f"âŒ Erreur envoi: {response.text}")
            return {"success": False, "error": response.text}
            
    except Exception as e:
        logger.error(f"âŒ Exception envoi: {e}")
        return {"success": False, "error": str(e)}

@app.route("/health", methods=['GET'])
def health_check():
    """Health check avec infos dÃ©taillÃ©es"""
    return jsonify({
        "status": "healthy",
        "bot": "NakamaBot Otaku Edition",
        "timestamp": datetime.now().isoformat(),
        "commands_count": len(COMMANDS),
        "commands_list": list(COMMANDS.keys()),
        "ai_clients": len(active_clients),
        "active_quizzes": len(active_quizzes),
        "client_status": [{"name": c["name"], "models": len(c["models"])} for c in active_clients],
        "config": {
            "verify_token_set": bool(VERIFY_TOKEN),
            "page_token_set": bool(PAGE_ACCESS_TOKEN),
            "total_api_keys": len([c for c in API_CONFIGS if c["key"]])
        }
    }), 200

@app.route("/commands", methods=['GET'])
def list_commands():
    """API pour lister toutes les commandes disponibles"""
    commands_info = {}
    for name, info in COMMANDS.items():
        commands_info[name] = {
            'name': name,
            'description': info['description']
        }
    
    return jsonify({
        "total_commands": len(COMMANDS),
        "commands": commands_info,
        "ai_clients_active": len(active_clients)
    })

@app.route("/quiz/stats", methods=['GET'])
def quiz_stats():
    """Statistiques des quiz actifs"""
    with quiz_lock:
        stats = []
        for sender_id, quiz in active_quizzes.items():
            remaining = max(0, int((quiz.expires_at - datetime.now()).total_seconds()))
            stats.append({
                "sender_id": sender_id,
                "question": quiz.question[:50] + "..." if len(quiz.question) > 50 else quiz.question,
                "remaining_seconds": remaining,
                "answered": quiz.answered
            })
    
    return jsonify({
        "active_quizzes": len(active_quizzes),
        "quizzes": stats
    })

@app.route("/api/status", methods=['GET'])
def api_status():
    """Status dÃ©taillÃ© de tous les clients API"""
    clients_status = []
    
    for config in active_clients:
        try:
            # Test simple pour vÃ©rifier si le client fonctionne
            test_response = config["client"].chat.completions.create(
                model=config["models"][0],
                messages=[{"role": "user", "content": "test"}],
                max_tokens=1,
                timeout=5
            )
            status = "online"
        except Exception as e:
            status = f"error: {str(e)[:50]}"
        
        clients_status.append({
            "name": config["name"],
            "status": status,
            "models": config["models"],
            "base_url": config.get("base_url", "OpenAI default")
        })
    
    return jsonify({
        "timestamp": datetime.now().isoformat(),
        "total_clients": len(active_clients),
        "clients": clients_status
    })

# ğŸŒ NOUVELLES COMMANDES ULTRA-ATTRACTIVES ğŸŒ

@command('waifurat', 'ğŸ­ Ton classement personnel de waifus!')
def cmd_waifurat(sender_id, message_text=""):
    """SystÃ¨me de ranking de waifus personnel"""
    if not active_clients:
        return "âŒ Le systÃ¨me de ranking est offline!"
    
    if message_text.strip():
        waifu_name = message_text.strip()
        
        ai_response = get_ai_response([{
            "role": "system",
            "content": f"""L'utilisateur soumet '{waifu_name}' pour son ranking de waifus.
            
            RÃ©ponds avec :
            - Note sur 10 avec justification otaku
            - Analyse des qualitÃ©s de cette waifu
            - Comparaison subtile avec d'autres waifus populaires
            - Style passionnÃ© et expert
            - Encourage Ã  soumettre d'autres waifus
            - Maximum 400 caractÃ¨res"""
        }, {
            "role": "user",
            "content": f"Rate cette waifu: {waifu_name}"
        }], max_tokens=200, temperature=0.8)
        
        if ai_response:
            return f"ğŸ­ğŸ“Š WAIFU RATING!\n\n{ai_response}\n\nâ­ Soumets d'autres waifus avec /waifurat [nom]!"
        else:
            return f"ğŸ­ {waifu_name}? Excellent taste! 9/10 pour moi! ğŸ’•\n\nğŸ“Š Continue ton ranking avec /waifurat [autre waifu]!"
    
    return "ğŸ­â­ WAIFU RATING SYSTEM!\n\nğŸ’• Soumets tes waifus prÃ©fÃ©rÃ©es et je les raterai comme un vrai connaisseur!\n\nğŸ¯ Ex: /waifurat Nezuko\nâœ¨ Ex: /waifurat Zero Two\n\nğŸ“Š Construis ton tier list personnel!"

@command('animemood', 'ğŸ­ Anime parfait selon ton humeur!')
def cmd_animemood(sender_id, message_text=""):
    """Recommandation basÃ©e sur l'humeur"""
    if not active_clients:
        return "âŒ Le mood detector est en panne!"
    
    mood = message_text.strip() or "alÃ©atoire"
    
    ai_response = get_ai_response([{
        "role": "system",
        "content": f"""L'utilisateur se sent '{mood}'. Recommande 2-3 anime parfaits pour cette humeur avec :
        - Analyse psychologique de pourquoi ces anime matchent l'humeur
        - Descriptions Ã©motionnelles des anime
        - Impact thÃ©rapeutique/Ã©motionnel
        - Style empathique et expert
        - Maximum 450 caractÃ¨res"""
    }, {
        "role": "user",
        "content": f"Je me sens {mood}, quel anime regarder?"
    }], max_tokens=230, temperature=0.8)
    
    if ai_response:
        return f"ğŸ­ğŸ’« MOOD MATCH!\n\n{ai_response}\n\nğŸŒŸ Ton mood va changer avec ces pÃ©pites!"
    else:
        return f"ğŸ­ Mood: {mood}?\n\nâœ¨ Je recommande:\nâ€¢ Your Name (Ã©motions pures) ğŸ˜­\nâ€¢ Mob Psycho (dÃ©veloppement perso) ğŸ’ª\nâ€¢ Nichijou (pur fun) ğŸ˜‚\n\nğŸ’« Perfect match pour ton Ã©tat d'esprit!"

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    
    logger.info("ğŸš€ DÃ©marrage NakamaBot Otaku Edition Enhanced...")
    logger.info(f"ğŸŒ Commandes chargÃ©es: {len(COMMANDS)}")
    logger.info(f"ğŸ“‹ Liste: {list(COMMANDS.keys())}")
    logger.info(f"ğŸ¤– Clients AI actifs: {len(active_clients)}")
    logger.info(f"ğŸ”§ Configurations API: {[c['name'] for c in active_clients]}")
    
    app.run(host="0.0.0.0", port=port, debug=False)
